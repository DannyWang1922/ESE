{
    "model_name_or_path": "google-bert/bert-base-uncased",
    "pretrained_model_path": null,
    "pretrained_lora_path": null,
    "train_name_or_path": null,
    "train_subset_name": null,
    "train_split_name": "train",
    "valid_name_or_path": "mteb/stsbenchmark-sts",
    "valid_subset_name": null,
    "valid_split_name": "test",
    "prompt_template": null,
    "save_dir": "./train_result/bert_moe_base_11",
    "seed": 42,
    "dataset_seed": 42,
    "workers": 16,
    "cosine_w": 0.0,
    "ibn_w": 1.0,
    "angle_w": 0.02,
    "angle_tau": 20.0,
    "cosine_tau": 20.0,
    "ibn_tau": 20.0,
    "apply_lora": 0,
    "load_kbit": null,
    "lora_r": 32,
    "lora_alpha": 32,
    "lora_dropout": 0.1,
    "lora_target_modules": null,
    "learning_rate": 5e-05,
    "warmup_steps": 100,
    "logging_steps": 100,
    "pooling_strategy": "cls",
    "tokenizer_padding_side": null,
    "epochs": 5,
    "max_steps": -1,
    "save_steps": 1000,
    "batch_size": 16,
    "maxlen": 512,
    "streaming": false,
    "gradient_accumulation_steps": 1,
    "torch_dtype": null,
    "fp16": null,
    "push_to_hub": 0,
    "hub_private_repo": 1,
    "hub_model_id": null,
    "is_llm": 0,
    "apply_billm": 0,
    "billm_model_class": null,
    "apply_ese": 0,
    "ese_kl_temperature": 1.0,
    "ese_compression_size": 128,
    "teacher_name_or_path": null,
    "teacher_pooling_strategy": "cls",
    "wandb_project": null,
    "wandb_log_model": "false",
    "config": "config/bert_moe_base_11.yaml",
    "use_bert_moe": 1,
    "num_experts": 8,
    "top_k": 2,
    "expert_dropout": 0.1,
    "router_temperature": 0.1,
    "router_noise_epsilon": 0.01,
    "router_training_noise": true,
    "use_load_balancing": true,
    "router_z_loss_coef": 0.001,
    "router_aux_loss_coef": 0.01,
    "track_expert_metrics": true,
    "moe_layers": [
        11
    ],
    "expert_init_strategy": "diverse",
    "parallel_expert_computation": false,
    "max_train_samples": 100000,
    "max_valid_samples": null
}